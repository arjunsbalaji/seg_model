{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectron2 OCT for SOTA comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to COCOify the dataset so see jpg to COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import detectron2\n",
    "\n",
    "import os, sys, time, random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pycocotools.coco import COCO\n",
    "import cv2\n",
    "\n",
    "from detectron2.data.datasets import load_coco_json\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.evaluation import DatasetEvaluator,DatasetEvaluators\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectname = 'OCT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/workspace/oct_ca_seg/COCOdata/')\n",
    "train_path = data_path/'train'\n",
    "valid_path = data_path/'valid'\n",
    "test_path = data_path/'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.29s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "trainCOCO = COCO(train_path/'images/annotations.json')\n",
    "validCOCO = COCO(valid_path/'images/annotations.json')\n",
    "testCOCO = COCO(valid_path/'images/annotations.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDetectronDataset = load_coco_json(train_path/('images/annotations.json'), train_path/'images', dataset_name=train_path.name)\n",
    "validDetectronDataset = load_coco_json(valid_path/('images/annotations.json'), valid_path/'images', dataset_name=valid_path.name)\n",
    "testDetectronDataset = load_coco_json(test_path/('images/annotations.json'), test_path/'images', dataset_name=test_path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [train_path, valid_path, test_path]:\n",
    "    DatasetCatalog.register(projectname + d.name,\n",
    "                            lambda d=d: load_coco_json(d/('images/annotations.json'), d/'images', dataset_name=d.name))  #get_dicts(d.name))#\n",
    "    MetadataCatalog.get(projectname+ d.name).set(stuff_classes=[\"lumen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = MetadataCatalog.get(projectname+'train')\n",
    "train_metadata.stuff_classes = ['lumen']\n",
    "train_metadata.thing_classes = ['lumen']\n",
    "valid_metadata = MetadataCatalog.get(projectname+'valid')\n",
    "valid_metadata.stuff_classes = ['lumen']\n",
    "valid_metadata.thing_classes = ['lumen']\n",
    "test_metadata = MetadataCatalog.get(projectname+'test')\n",
    "test_metadata.stuff_classes = ['lumen']\n",
    "test_metadata.thing_classes = ['lumen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for d in random.sample(testDetectronDataset, 1):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=1)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    plt.imshow(vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (projectname+\"train\",)\n",
    "cfg.DATASETS.TEST = (projectname+\"valid\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 1  # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)\n",
    "cfg.OUTPUT_DIR = '/workspace/oct_ca_seg/runsaves/initPawsey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(Path('/workspace/oct_ca_seg/runsaves/01_pawsey/01_OCTPawsey_model_mask_rcnn_R_50_FPN_3x.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'EXPECTED_RESULTS': [], 'EVAL_PERIOD': 0, 'KEYPOINT_OKS_SIGMAS': [], 'DETECTIONS_PER_IMAGE': 100, 'AUG': CfgNode({'ENABLED': False, 'MIN_SIZES': (400, 500, 600, 700, 800, 900, 1000, 1100, 1200), 'MAX_SIZE': 4000, 'FLIP': True}), 'PRECISE_BN': CfgNode({'ENABLED': False, 'NUM_ITER': 200})})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves the config in the out put directory be careful because of this youll override if retraining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cfg.OUTPUT_DIR +'/initialOCTPawsey_model_mask_rcnn_R_50_FPN_3x.yaml', 'w') as file:\n",
    "    file.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/28 09:04:51 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[05/28 09:04:52 d2.data.datasets.coco]: \u001b[0mLoaded 8410 images in COCO format from /workspace/oct_ca_seg/COCOdata/train/images/annotations.json\n",
      "\u001b[32m[05/28 09:04:52 d2.data.common]: \u001b[0mSerializing 8410 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/28 09:04:52 d2.data.common]: \u001b[0mSerialized dataset takes 7.55 MiB\n",
      "\u001b[32m[05/28 09:04:52 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[05/28 09:04:52 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_f10217.pkl: 178MB [00:21, 8.38MB/s]                              \n",
      "'roi_heads.box_predictor.cls_score.weight' has shape (81, 1024) in the checkpoint but (2, 1024) in the model! Skipped.\n",
      "'roi_heads.box_predictor.cls_score.bias' has shape (81,) in the checkpoint but (2,) in the model! Skipped.\n",
      "'roi_heads.box_predictor.bbox_pred.weight' has shape (320, 1024) in the checkpoint but (4, 1024) in the model! Skipped.\n",
      "'roi_heads.box_predictor.bbox_pred.bias' has shape (320,) in the checkpoint but (4,) in the model! Skipped.\n",
      "'roi_heads.mask_head.predictor.weight' has shape (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! Skipped.\n",
      "'roi_heads.mask_head.predictor.bias' has shape (80,) in the checkpoint but (1,) in the model! Skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/28 09:05:13 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[05/28 09:05:14 d2.data.datasets.coco]: \u001b[0mLoaded 2602 images in COCO format from /workspace/oct_ca_seg/COCOdata/valid/images/annotations.json\n",
      "\u001b[32m[05/28 09:05:14 d2.data.common]: \u001b[0mSerializing 2602 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/28 09:05:14 d2.data.common]: \u001b[0mSerialized dataset takes 2.22 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/28 09:05:14 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[05/28 09:05:14 d2.utils.events]: \u001b[0m eta: N/A  iter: 0  total_loss: 2.013  loss_cls: 0.773  loss_box_reg: 0.536  loss_mask: 0.693  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007    data_time: 0.1500  lr: 0.000000  max_mem: 1651M\n",
      "\u001b[32m[05/28 09:05:14 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def annsToSingleBinMask(cocoset, img_id):\n",
    "    anns = cocoset.imgToAnns[img_id]\n",
    "    if len(anns) == 0:\n",
    "        h, w = cocoset.imgs[img_id]['height'], cocoset.imgs[img_id]['width']\n",
    "        return np.zeros((h,w))\n",
    "    else:\n",
    "        masks = cocoset.annToMask(anns[0])\n",
    "        for ann in anns[1:]:\n",
    "            masks = masks + cocoset.annToMask(ann) #assumption that lumen annotations never overlap\n",
    "        return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lossdice(c,l, iou:bool=False, eps:float=1e-8):\n",
    "    \"Dice coefficient metric for binary target. If iou=True, returns iou metric, classic for segmentation problems.\"\n",
    "    n = l.shape[0]\n",
    "    c = c.view(n,-1).float()\n",
    "    l = l.view(n,-1)\n",
    "    intersect = (c * l).sum().float()\n",
    "    union = (c+l).sum().float()\n",
    "    if not iou: return (2. * intersect / union if union > 0 else union.new([1.]).squeeze())\n",
    "    else: return (intersect / (union-intersect+eps) if union > 0 else union.new([1.]).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Sens(c, l):\n",
    "    #returns sens of argmaxxed predition. \n",
    "    #print(c.size(), l.size())\n",
    "    n_targs=l.size()[0]\n",
    "    c =(c.view(n_targs, -1) > 0).float()\n",
    "    l=(l.view(n_targs, -1) > 0).float()\n",
    "    inter = torch.sum(c*l, dim=(1))\n",
    "    union = torch.sum(c, dim=(1)) + torch.sum(l, dim=1) - inter\n",
    "    #print(inter.size(), union.size())\n",
    "    return inter/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Spec(c,l):\n",
    "    #returns sens of argmaxxed predition. \n",
    "    n_targs=l.size()[0]\n",
    "    c =(c.view(n_targs, -1) > 0).float()\n",
    "    l=(l.view(n_targs, -1) > 0).float()\n",
    "    c = 1-c\n",
    "    l=1-l\n",
    "    inter = torch.sum(c*l, dim=(1))\n",
    "    union = torch.sum(c, dim=(1)) + torch.sum(l, dim=1) - inter\n",
    "    return inter/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Acc(c, l):\n",
    "    n_targs=l.size()[0]\n",
    "    c =(c.view(n_targs, -1) > 0).float()\n",
    "    l=(l.view(n_targs, -1) > 0).float()\n",
    "    c = torch.sum(torch.eq(c,l).float(),dim=1)\n",
    "    return (c/l.size()[-1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OCT_Evaluator(DatasetEvaluator):\n",
    "    def __init__(self, validset):\n",
    "        self.validset = validset\n",
    "        \n",
    "    def reset(self):\n",
    "        self.dices = {} \n",
    "        self.sens = {} \n",
    "        self.specs = {} \n",
    "        self.accs = {} \n",
    "        self.scores = {}\n",
    "        \n",
    "    def process(self, inputs, outputs):\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            id = input['image_id']\n",
    "            pred_masks = output['instances'].pred_masks.clone().detach().int()\n",
    "            pred_masks = pred_masks.sum(dim=0).unsqueeze(0)\n",
    "            pred_masks = (pred_masks>0).float()\n",
    "            labels = torch.tensor(annsToSingleBinMask(self.validset, id)).cuda().unsqueeze(0)\n",
    "            #labels = torch.tensor(self.validset.annToMask(self.validset.anns[id])).cuda().unsqueeze(0)\n",
    "            #print(pred_masks.size(), labels.size())\n",
    "            self.dices[id] = lossdice(pred_masks, labels).cpu().item()\n",
    "            #print(Sens(pred_masks, labels).cpu().size())\n",
    "            self.sens[id] = Sens(pred_masks, labels).cpu().item()\n",
    "            self.specs[id] = Spec(pred_masks, labels).cpu().item()\n",
    "            self.accs[id] = Acc(pred_masks, labels).cpu().item()\n",
    "            \n",
    "            if len(output['instances'].scores) == 0: scores = None\n",
    "            elif len(output['instances'].scores) > 0: scores = list(output['instances'].scores.cpu().numpy()) \n",
    "    def evaluate(self):\n",
    "        # save self.count somewhere, or print it, or return it.\n",
    "        return {\"dices\": self.dices,\n",
    "                \"accs\": self.accs,\n",
    "                \"sens\": self.sens,\n",
    "                \"specs\": self.specs,\n",
    "                \"scores\": self.scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "\n",
    "coco_ev = COCOEvaluator(projectname+\"valid\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "OCT_ev = OCT_Evaluator(validCOCO)\n",
    "\n",
    "evaluators = DatasetEvaluators([coco_ev, OCT_ev])\n",
    "val_loader = build_detection_test_loader(cfg, projectname+\"valid\")\n",
    "results = inference_on_dataset(predictor.model, val_loader, evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ./notebook2script.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"./notebook2script.py\", line 3, in <module>\n",
      "    import json,fire,re\n",
      "ModuleNotFoundError: No module named 'fire'\n"
     ]
    }
   ],
   "source": [
    "! ./notebook2script.py ./detectron.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
