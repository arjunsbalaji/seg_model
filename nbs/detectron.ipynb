{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectron2 OCT for SOTA comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to COCOify the dataset so see jpg to COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import detectron2\n",
    "\n",
    "import os, sys, time, random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pycocotools.coco import COCO\n",
    "import cv2\n",
    "\n",
    "from detectron2.data.datasets import load_coco_json\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.evaluation import DatasetEvaluator,DatasetEvaluators\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectname = 'OCT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/workspace/oct_ca_seg/COCOdata/')\n",
    "train_path = data_path/'train'\n",
    "valid_path = data_path/'valid'\n",
    "test_path = data_path/'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.29s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.07s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "trainCOCO = COCO(train_path/'images/annotations.json')\n",
    "validCOCO = COCO(valid_path/'images/annotations.json')\n",
    "testCOCO = COCO(valid_path/'images/annotations.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDetectronDataset = load_coco_json(train_path/('images/annotations.json'), train_path/'images', dataset_name=train_path.name)\n",
    "validDetectronDataset = load_coco_json(valid_path/('images/annotations.json'), valid_path/'images', dataset_name=valid_path.name)\n",
    "testDetectronDataset = load_coco_json(test_path/('images/annotations.json'), test_path/'images', dataset_name=test_path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [train_path, valid_path, test_path]:\n",
    "    DatasetCatalog.register(projectname + d.name,\n",
    "                            lambda d=d: load_coco_json(d/('images/annotations.json'), d/'images', dataset_name=d.name))  #get_dicts(d.name))#\n",
    "    MetadataCatalog.get(projectname+ d.name).set(stuff_classes=[\"lumen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = MetadataCatalog.get(projectname+'train')\n",
    "train_metadata.stuff_classes = ['lumen']\n",
    "train_metadata.thing_classes = ['lumen']\n",
    "valid_metadata = MetadataCatalog.get(projectname+'valid')\n",
    "valid_metadata.stuff_classes = ['lumen']\n",
    "valid_metadata.thing_classes = ['lumen']\n",
    "test_metadata = MetadataCatalog.get(projectname+'test')\n",
    "test_metadata.stuff_classes = ['lumen']\n",
    "test_metadata.thing_classes = ['lumen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for d in random.sample(testDetectronDataset, 1):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=1)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    plt.imshow(vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (projectname+\"train\",)\n",
    "cfg.DATASETS.TEST = (projectname+\"valid\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 1  # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)\n",
    "cfg.OUTPUT_DIR = '/workspace/oct_ca_seg/runsaves/initPawsey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(Path('/workspace/oct_ca_seg/runsaves/01_pawsey/01_OCTPawsey_model_mask_rcnn_R_50_FPN_3x.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves the config in the out put directory be careful because of this youll override if retraining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cfg.OUTPUT_DIR +'/initialOCTPawsey_model_mask_rcnn_R_50_FPN_3x.yaml', 'w') as file:\n",
    "    file.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/28 09:04:51 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[05/28 09:04:52 d2.data.datasets.coco]: \u001b[0mLoaded 8410 images in COCO format from /workspace/oct_ca_seg/COCOdata/train/images/annotations.json\n",
      "\u001b[32m[05/28 09:04:52 d2.data.common]: \u001b[0mSerializing 8410 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/28 09:04:52 d2.data.common]: \u001b[0mSerialized dataset takes 7.55 MiB\n",
      "\u001b[32m[05/28 09:04:52 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[05/28 09:04:52 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_f10217.pkl: 178MB [00:21, 8.38MB/s]                              \n",
      "'roi_heads.box_predictor.cls_score.weight' has shape (81, 1024) in the checkpoint but (2, 1024) in the model! Skipped.\n",
      "'roi_heads.box_predictor.cls_score.bias' has shape (81,) in the checkpoint but (2,) in the model! Skipped.\n",
      "'roi_heads.box_predictor.bbox_pred.weight' has shape (320, 1024) in the checkpoint but (4, 1024) in the model! Skipped.\n",
      "'roi_heads.box_predictor.bbox_pred.bias' has shape (320,) in the checkpoint but (4,) in the model! Skipped.\n",
      "'roi_heads.mask_head.predictor.weight' has shape (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! Skipped.\n",
      "'roi_heads.mask_head.predictor.bias' has shape (80,) in the checkpoint but (1,) in the model! Skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/28 09:05:13 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[05/28 09:05:14 d2.data.datasets.coco]: \u001b[0mLoaded 2602 images in COCO format from /workspace/oct_ca_seg/COCOdata/valid/images/annotations.json\n",
      "\u001b[32m[05/28 09:05:14 d2.data.common]: \u001b[0mSerializing 2602 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/28 09:05:14 d2.data.common]: \u001b[0mSerialized dataset takes 2.22 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/28 09:05:14 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[05/28 09:05:14 d2.utils.events]: \u001b[0m eta: N/A  iter: 0  total_loss: 2.013  loss_cls: 0.773  loss_box_reg: 0.536  loss_mask: 0.693  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007    data_time: 0.1500  lr: 0.000000  max_mem: 1651M\n",
      "\u001b[32m[05/28 09:05:14 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def annsToSingleBinMask(cocoset, img_id):\n",
    "    anns = cocoset.imgToAnns[img_id]\n",
    "    if len(anns) == 0:\n",
    "        h, w = cocoset.imgs[img_id]['height'], cocoset.imgs[img_id]['width']\n",
    "        return np.zeros((h,w))\n",
    "    else:\n",
    "        masks = cocoset.annToMask(anns[0])\n",
    "        for ann in anns[1:]:\n",
    "            masks = masks + cocoset.annToMask(ann) #assumption that lumen annotations never overlap\n",
    "        return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lossdice(c,l, iou:bool=False, eps:float=1e-8):\n",
    "    \"Dice coefficient metric for binary target. If iou=True, returns iou metric, classic for segmentation problems.\"\n",
    "    n = l.shape[0]\n",
    "    c = c.view(n,-1).float()\n",
    "    l = l.view(n,-1)\n",
    "    intersect = (c * l).sum().float()\n",
    "    union = (c+l).sum().float()\n",
    "    if not iou: return (2. * intersect / union if union > 0 else union.new([1.]).squeeze())\n",
    "    else: return (intersect / (union-intersect+eps) if union > 0 else union.new([1.]).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Sens(c, l):\n",
    "    #returns sens of argmaxxed predition. \n",
    "    #print(c.size(), l.size())\n",
    "    n_targs=l.size()[0]\n",
    "    c =(c.view(n_targs, -1) > 0).float()\n",
    "    l=(l.view(n_targs, -1) > 0).float()\n",
    "    inter = torch.sum(c*l, dim=(1))\n",
    "    union = torch.sum(c, dim=(1)) + torch.sum(l, dim=1) - inter\n",
    "    #print(inter.size(), union.size())\n",
    "    return inter/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Spec(c,l):\n",
    "    #returns sens of argmaxxed predition. \n",
    "    n_targs=l.size()[0]\n",
    "    c =(c.view(n_targs, -1) > 0).float()\n",
    "    l=(l.view(n_targs, -1) > 0).float()\n",
    "    c = 1-c\n",
    "    l=1-l\n",
    "    inter = torch.sum(c*l, dim=(1))\n",
    "    union = torch.sum(c, dim=(1)) + torch.sum(l, dim=1) - inter\n",
    "    return inter/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Acc(c, l):\n",
    "    n_targs=l.size()[0]\n",
    "    c =(c.view(n_targs, -1) > 0).float()\n",
    "    l=(l.view(n_targs, -1) > 0).float()\n",
    "    c = torch.sum(torch.eq(c,l).float(),dim=1)\n",
    "    return (c/l.size()[-1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OCT_Evaluator(DatasetEvaluator):\n",
    "    def __init__(self, validset):\n",
    "        self.validset = validset\n",
    "        \n",
    "    def reset(self):\n",
    "        self.dices = {} \n",
    "        self.sens = {} \n",
    "        self.specs = {} \n",
    "        self.accs = {} \n",
    "        self.scores = {}\n",
    "        \n",
    "    def process(self, inputs, outputs):\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            id = input['image_id']\n",
    "            pred_masks = output['instances'].pred_masks.clone().detach().int()\n",
    "            pred_masks = pred_masks.sum(dim=0).unsqueeze(0)\n",
    "            pred_masks = (pred_masks>0).float()\n",
    "            labels = torch.tensor(annsToSingleBinMask(self.validset, id)).cuda().unsqueeze(0)\n",
    "            #labels = torch.tensor(self.validset.annToMask(self.validset.anns[id])).cuda().unsqueeze(0)\n",
    "            #print(pred_masks.size(), labels.size())\n",
    "            self.dices[id] = lossdice(pred_masks, labels).cpu().item()\n",
    "            #print(Sens(pred_masks, labels).cpu().size())\n",
    "            self.sens[id] = Sens(pred_masks, labels).cpu().item()\n",
    "            self.specs[id] = Spec(pred_masks, labels).cpu().item()\n",
    "            self.accs[id] = Acc(pred_masks, labels).cpu().item()\n",
    "            \n",
    "            if len(output['instances'].scores) == 0: scores = None\n",
    "            elif len(output['instances'].scores) > 0: scores = list(output['instances'].scores.cpu().numpy()) \n",
    "    def evaluate(self):\n",
    "        # save self.count somewhere, or print it, or return it.\n",
    "        return {\"dices\": self.dices,\n",
    "                \"accs\": self.accs,\n",
    "                \"sens\": self.sens,\n",
    "                \"specs\": self.specs,\n",
    "                \"scores\": self.scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "\n",
    "coco_ev = COCOEvaluator(projectname+\"valid\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "OCT_ev = OCT_Evaluator(validCOCO)\n",
    "\n",
    "evaluators = DatasetEvaluators([coco_ev, OCT_ev])\n",
    "val_loader = build_detection_test_loader(cfg, projectname+\"valid\")\n",
    "results = inference_on_dataset(predictor.model, val_loader, evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ./notebook2script.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"./notebook2script.py\", line 3, in <module>\n",
      "    import json,fire,re\n",
      "ModuleNotFoundError: No module named 'fire'\n"
     ]
    }
   ],
   "source": [
    "! ./notebook2script.py ./detectron.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
